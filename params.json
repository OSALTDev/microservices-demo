{"name":"Microservices-demo with Docker Swarm and HA Proxy (Interlock)","tagline":"A very simple Go-Redis app to demo discovery of multiple services behind a haproxy load balanced (using the interlock plugin system)","body":"# microservices-demo\r\nA very simple Go-Redis app to demo discovery of multiple services behind a haproxy load balanced (using the interlock plugin system).\r\n\r\nThis demo uses Docker Swarm, docker-compose and HA Proxy as the load balancer service through the interlock plugin system. If you need a simpler demo that does not use docker-compose, try [the interlock-demo](http://anokun7.github.io/interlock-demo/).\r\n\r\n### Pre-requisites\r\n1. Ensure Docker Swarm is working. An effective demo would require at least 3 active nodes in the swarm.\r\n2. Docker version > 1.8\r\n3. Set the `DOCKER_HOST` environment variable to the Docker Swarm's tcp endpoint. Do not use localhost, even if you are on the Docker Swarm manager / master. Example: `export DOCKER_HOST=tcp://10.0.0.6:9999`.\r\n4. `docker info` should show the nodes added to the cluster.\r\n\r\n### Steps\r\n1. On any node that is part of the cluster, run a container from the ehazlett/interlock image using the command below. We want to use the haproxy plugin for this lab.\r\n  ```\r\n  docker run -p 80:80 --name lb0 -d ehazlett/interlock --swarm-url $DOCKER_HOST --plugin haproxy start\r\n  ```\r\n2. Due to the cluster scheduling, the haproxy container may actually be running on a different host than the one where the above command was run. Use `docker ps | grep lb0` to identify the host it is running on.\r\n  - Alternatively, specify a filter (ie., affinity:nodename or constraint:container) to restrict the container to a specific docker host.\r\n3. Clone this repo to a local folder. `git clone https://github.com/anokun7/microservices-demo.git`\r\n4. `cd microservices-demo`\r\n5. Use docker-compose to build and run the web app containers. `docker-compose up -d`\r\n\r\n  ```\r\n  vagrant@ubuntu5:/vagrant/microservices-demo$ docker-compose up -d \r\n  Creating microservicesdemo_dbdata_1...\r\n  Creating microservicesdemo_db_1...\r\n  Creating microservicesdemo_web_1...\r\n  ```\r\n6. Every container started in a swarm cluster gets registered to the ha-proxy as a backend as long as the container has an exposed port and a hostname.\r\n  - The hostname for the `web` container is configured in the `docker-compose.yml` using the `INTERLOCK_DATA` environment variable.\r\n7. Let's again use docker-compose to scale up the number of web containers to 9. Each of these 9 web containers will also get registered to the same backend in the HA Proxy config.\r\n \r\n  ```\r\n  vagrant@ubuntu5:/vagrant/microservices-demo$ docker-compose scale web=9\r\n  Creating microservicesdemo_web_2...\r\n  Creating microservicesdemo_web_3...\r\n  Creating microservicesdemo_web_4...\r\n  Creating microservicesdemo_web_5...\r\n  Creating microservicesdemo_web_6...\r\n  Creating microservicesdemo_web_7...\r\n  Creating microservicesdemo_web_8...\r\n  Creating microservicesdemo_web_9...\r\n  Starting microservicesdemo_web_2...\r\n  Starting microservicesdemo_web_3...\r\n  Starting microservicesdemo_web_4...\r\n  Starting microservicesdemo_web_5...\r\n  Starting microservicesdemo_web_6...\r\n  Starting microservicesdemo_web_7...\r\n  Starting microservicesdemo_web_8...\r\n  Starting microservicesdemo_web_9...\r\n  ```\r\n  - Tha HA Proxy stats page should (auto) refresh to show the newly registered backends, like below:\r\n  ![HA Proxy stats](https://farm1.staticflickr.com/651/21717537885_0c6a3ec632_b.jpg)\r\n8. Ensure DNS is setup (or add entries to `/etc/hosts` file) to resolve the host where the `lb0` container is running.\r\n9. Browse to the URL: `http://[host-ip-running-lb0]/demo`\r\n  - <img src=\"https://farm1.staticflickr.com/666/21705956952_9b3bfea89f_b.jpg\" width=300>\r\n10. Every time a container responds to the HTTP request, it should get its counter incremented. The counter is being stored (and retrieved) from a REDIS backend database.","google":"UA-1020564-1","note":"Don't delete this file! It's used internally to help with page regeneration."}